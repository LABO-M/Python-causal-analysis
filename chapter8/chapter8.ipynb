{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07e152a",
   "metadata": {},
   "source": [
    "# 第8章 ディープラーニングを用いた因果探索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d401c5",
   "metadata": {},
   "source": [
    "#### ・本章ではディープラーニングを用いた因果探索について解説、実装する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff55336",
   "metadata": {},
   "source": [
    "## 8-1 因果探索とGAN(Generative Adversarial Networks)の関係"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b69113",
   "metadata": {},
   "source": [
    "#### ・2020年において、因果推論の分野でもディープラーニングを利用した研究が進んでいる .　具体例として、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804556ba",
   "metadata": {},
   "source": [
    "#### グラフニューラルネットワークを用いた因果探索\n",
    "#### 深層強化学習を用いた因果探索\n",
    "#### GAN(Generative Adversarial Networks)を用いた因果探索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c66484",
   "metadata": {},
   "source": [
    "#### などが挙げられる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bfa1f5",
   "metadata": {},
   "source": [
    "#### ・本章ではディープラーニングを用いた因果探索手法の中でも、\"SAM(Structural Agnostic Model)\"について解説、実装する .　SAMはGANを用いた因果探索手法である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed9288",
   "metadata": {},
   "source": [
    "#### ・本章の内容はPyTorchを用いたディープラーニングとGANの実装経験がないと理解が難しい部分が多いらしいです ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09852be0",
   "metadata": {},
   "source": [
    "#### ・本章で出てくる実装はSAM論文の著者らのGitHubのコードを一部参考、使用している ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9670a",
   "metadata": {},
   "source": [
    "![alt text](pict1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4a047",
   "metadata": {},
   "source": [
    "## GAN(Generative Adversarial Networks)とは"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f574dcb8",
   "metadata": {},
   "source": [
    "#### ・GANは大量の画像データを学習に使用し、実際には存在していない架空の画像を生成する技術として有名である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625c059",
   "metadata": {},
   "source": [
    "#### GANは生成器(Generator,以下G)と呼ばれるニューラルネットワークと、識別器(Discriminator,以下D)と呼ばれる2種類のニューラルネットワークから構成される ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59308f1e",
   "metadata": {},
   "source": [
    "#### ・画像を生成する際に使用するのは、「学習済みの生成器G」のみである .　学習済みの生成器Gに入力としてノイズを与えると、そのノイズの値に応じた架空の画像データが生成され、Gから出力される ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ab688",
   "metadata": {},
   "source": [
    "#### 例えば、入力ノイズの次元が20次元、出力される画像のサイズが縦横30ピクセルずつであれば、テンソルサイズ[20]のノイズ入力を入力として、テンソルサイズ[3,30,30]の出力を作り出す .　出力テンソルの最初の次元の3はRGBの各色チャンネルを示す ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569c95e",
   "metadata": {},
   "source": [
    "#### ・学習済み生成器Gを作る際に、手書き数字の画像を学習データとして与えた場合、手書き数字の画像を出力するような生成器Gを構築できる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1887a4b",
   "metadata": {},
   "source": [
    "#### また、GANの種類によっては入力にノイズだけでなく、条件(手書き数字画像であれば0や1など数字の種類を指定)を入力する場合がある .　この場合は条件に応じた任意の数字の画像を生成させることができる(Conditional GANと呼ぶ .) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d04dcd",
   "metadata": {},
   "source": [
    "### ・ここで重要な点は、\"生成器Gはノイズを入力に人が数字と認識できる画像を生成してくれる\"点である .　例えば、3×30×30の画像サイズにおいて、各値は0から255の256通りの値をとるため、生成できる画像パターンは膨大になる .　この膨大なパターンの中から、人が見たときに手書き数字画像と思えるパターンを出力してくれるのが生成器Gである ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54997e4",
   "metadata": {},
   "source": [
    "#### このとき、生成される画像は基本的には学習に使用した画像には含まれていないパターンの画像となる .　学習に使用した画像を表示するのではなく、学習に使用した画像の特徴をもった、新たな画像を生成してくれる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5f735",
   "metadata": {},
   "source": [
    "#### ・では、そのような生成器Gを構築するために生成器Gのニューラルネットワークをどのように学習させれば良いかが問題となる .　ここで識別器Dが登場する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede6a12",
   "metadata": {},
   "source": [
    "#### 生成器Gが生成した画像が数字に見えるかどうかを、いちいち人が判定することは大変で時間的にも困難なので、識別器Dが人に代わって、「生成器Gが生成した画像が数字に見えるかどうか」を判定する .　正確には、「数字に見えるかどうか」の判定は難しいので、「学習データセットにある画像か、それともGで生成された画像か？」を判定させる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05fdb32",
   "metadata": {},
   "source": [
    "### 識別器Dが学習データセットにある画像かGで生成された画像かうまく区別が付かないようになれば、Gで生成される画像は学習データの特徴をもった、人が見ても手書き数字に見える画像だと判断できる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c9fb8",
   "metadata": {},
   "source": [
    "#### ・この学習の際に、識別器Dは学習データセットの画像と生成画像の判定がうまくできない状態からスタートし、生成器Gもまるで砂嵐のような画像しか生成できない状態からスタートする ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5a2a0",
   "metadata": {},
   "source": [
    "#### そして、生成器Gは「識別器Dが学習データセットの画像と勘違いする画像を生成するように」、識別器Dは「学習データセットにある画像か、それとも生成された画像か判定できるように」、それぞれのニューラルネットワークを更新していく ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd41ad4",
   "metadata": {},
   "source": [
    "#### 識別器Dも初期状態からスタートする理由は、はじめから完璧にGの生成画像を見抜かれてしまうと、Gの学習がうまくいかないからである .　DとGを徐々に切磋琢磨させながら、学習を進める ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321537e9",
   "metadata": {},
   "source": [
    "#### ・これらを踏まえると、最終的に学習済み生成器Gは人が見たときに、学習データセットにある画像のような画像を生成できるようになる .　これがGANの大まかなイメージである ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd6791",
   "metadata": {},
   "source": [
    "#### ・本章の因果探索の場合では、「観測したデータと同じような特徴のデータを生み出す生成器Gを学習させることができれば、この生成器Gから観測データが生まれるしくみを解き明かし、因果ダイアグラムを描くことができる .　これが因果探索にGANを用いるモチベーションとなる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4329fe",
   "metadata": {},
   "source": [
    "## 8-2 SAM(Structural Agnostic Model)の概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5cfc7e",
   "metadata": {},
   "source": [
    "#### ・本節では、GANを用いた因果探索手法であるSAM(Structural Agnostic Model)の、生成器Gおよび識別器Dの概要を、図を用いて解説する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aaa0b5",
   "metadata": {},
   "source": [
    "## 識別器Dのネットワーク構造"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05671f",
   "metadata": {},
   "source": [
    "#### ・初めに識別器Dのネットワーク構造について解説する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d7a32",
   "metadata": {},
   "source": [
    "#### ・識別器Dへの入力テンソルサイズは[mini_batch数,観測変数の数]である .　この入力テンソルの要素の値は観測データの変数の値であり、事前に標準化しておく ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34136c7",
   "metadata": {},
   "source": [
    "#### ・識別器Dの出力テンソルはサイズが[mini_batch数,1]である .　出力テンソルのサイズ1は、「入力データが学習データセットに含まれているものか(すなわち実際に観測したものか)、それとも生成器Gが生成したものか」を判定する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe38e4",
   "metadata": {},
   "source": [
    "#### このテンソルの値は、マイナスの値であれば、偽物の生成器が生成したデータと判定し、プラスの値であれば学習データセットに含まれていた観測データを意味する .　値の絶対値が大きければ大きいほど、その確信度が高くなる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d6cbb1",
   "metadata": {},
   "source": [
    "![alt text](pict2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539d55b",
   "metadata": {},
   "source": [
    "#### ・図8.2.1では入力データのミニバッチ数を2,000、観測データの変数の種類を6と仮定している .　入力データははじめに\"$L$\" と書かれた「線形全結合層(fully-connected Linear Layer)」に入る ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6192fe2",
   "metadata": {},
   "source": [
    "#### ここでは出力次元数は変数dnhで決められ、図8.2.1ではdnh=200としている ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d2f91",
   "metadata": {},
   "source": [
    "#### ・その後、データに1次元のバッチノーマライゼーションが実行される .　200次元になったミニバッチ2,000個のデータに対して、各200次元それぞれが平均0,標準偏差1になる変換を学習させる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1463ee",
   "metadata": {},
   "source": [
    "#### ・バッチノーマライゼーションのあと活性化関数のLeakyReLUで処理される .　一般的な活性化関数ReLUはマイナスの入力に対する出力が0になるが、LeakyReLUではマイナスの入力に対しても入力に応じた値(ここではPyTorchのデフォルトである0.2×入力値)が出力される ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503d710",
   "metadata": {},
   "source": [
    "#### ・活性化関数LeakyReLUを通ったデータのテンソルサイズは[2000,200]となっている .　その後、もう一度、線形全結合層、バッチノーマライゼーション、LeakyReLUに通す ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543da44",
   "metadata": {},
   "source": [
    "#### ・最後に線形全結合層(入力は200変数、出力は1変数)に通す .　この線形全結合層から出てくるテンソルが識別器Dの判定結果となり、テンソルサイズは[2000,1]となる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a6e5c",
   "metadata": {},
   "source": [
    "## 生成器Gの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3e8b6",
   "metadata": {},
   "source": [
    "#### ・識別器Dは一般的なGANで使用される構成とさほど変わらず、画像生成GANの識別器Dでは2次元(縦、横)のバッチノーマライゼーションであるところが、1次元バッチノーマライゼーションに代わっただけである ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e1d591",
   "metadata": {},
   "source": [
    "#### ・一方で生成器Gは、因果探索したいデータの生成過程を担い、変数間の因果ダイアグラムのつながりを求められる必要があるため、因果探索に対応した独特な形になる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece7d1f",
   "metadata": {},
   "source": [
    "#### ここで、SAMの生成器Gがどのようにデータを生成するのか、そして識別器Dがどのように生成データを判定するのかが重要である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbb65a",
   "metadata": {},
   "source": [
    "#### ・例えば観測変数が6種類あったとする ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79715bfa",
   "metadata": {},
   "source": [
    "### この場合SAMの生成器Gは、「6種類の変数の値6つを同時に1回で生成するのではなく、とある変数1つに着目し、残りの5つの変数には観測データを与え、入力ノイズに応じて、とある変数1つだけを生成する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449dfd6",
   "metadata": {},
   "source": [
    "### そして、識別器Dは「1つの変数の値がGでの生成データで、残りの5つが観測データのfakeケースと、6つ全てが観測データのケース、入力されたデータはこのどちらなのか？を判定する .」"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064d2ad",
   "metadata": {},
   "source": [
    "#### ・変数が6つある場合は、変数を変えながら上記の過程を6回実施する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75891a89",
   "metadata": {},
   "source": [
    "#### ・この内容を図解したのが図8.2.2になる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fca4e0",
   "metadata": {},
   "source": [
    "![alt text](pict3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa0d09",
   "metadata": {},
   "source": [
    "#### ・この生成器での生成データを識別器に入力するときには、図8.2.3のように工夫して与える .　識別器には生成データと一緒に観測データも与え、観測データから1種類の変数の値だけを生成データに置き換えて、それが生成されたデータと見破れるかを試す ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd0469",
   "metadata": {},
   "source": [
    "#### そのため、生成データを識別器に与える場合は、変数の数だけ識別器の判定結果が出る ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cae9b",
   "metadata": {},
   "source": [
    "![alt text](pict4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fa14b",
   "metadata": {},
   "source": [
    "## 生成器Gのネットワーク構造"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714328a",
   "metadata": {},
   "source": [
    "#### ・データ生成では、「ノイズを入力してとある1変数の値のみを生成データとして作成、その他の変数の値には観測データを与える」、これを変数の種類数だけ実施する .　この特殊なデータ生成のルールに応じて、ネットワークが複雑な構造をしている ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad6c69",
   "metadata": {},
   "source": [
    "#### ・生成器Gのポイントは、変数の種類数だけ生成過程を繰り返すが、実際に繰り返す時間がもったいないので、\"変数の種類数だけ生成過程を繰り返す操作を行列演算として実装する\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47eeec8",
   "metadata": {},
   "source": [
    "#### この操作を実行するために、PyTorchにはない独自のモジュールとして、Linear3DモジュールとChannelBatchNorm1dモジュールを使用する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0a6f3",
   "metadata": {},
   "source": [
    "#### これらのモジュールはSAMオリジナルである .　これらのモジュールがどのような操作をしているのかを解説する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877aff9",
   "metadata": {},
   "source": [
    "#### ・図8.2.4にSAMの生成器Gのネットワーク構造を示す .　最初のLinear3Dモジュールは基本的には単なる全結合層である .　ただし、1変数を除く観測されたデータとノイズを入力に、線形和の計算を実装する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b404e2",
   "metadata": {},
   "source": [
    "#### ・その後バッチノーマライゼーションで出力を標準化し、平均0、分散1に近づくように変換する .　この際に、BatchNorm1dを実行したいが、独自のLinear3Dの出力が、2次元ではなく3次元のテンソルになっていて、PyTorchのBatchNorm1dが適用できない ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59938008",
   "metadata": {},
   "source": [
    "#### そこで、内部で一度2次元にして、BatchNorm1dを適用し、再度元のテンソルサイズに戻すバッチノーマライゼーション操作として、ChannelBatchNorm1dモジュールを用意し、適用する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ac724",
   "metadata": {},
   "source": [
    "#### その後、再度Linear3Dによる線形変換を実施して、最終的に[minibatch数、変数の数]の生成データを出力する .　以上が、SAMでの生成器Gの大まかなネットワーク構造である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17b0f9",
   "metadata": {},
   "source": [
    "![alt text](pict5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720f846",
   "metadata": {},
   "source": [
    "#### ・次に、因果ダイアグラムの構造を生成器Gに取り込む方法について解説する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74712a",
   "metadata": {},
   "source": [
    "#### ・上記の図8.2.4の生成器のネットワーク概要図では掲載を省略しているが、生成器にはネットワーク構造のマトリクス$M$(SAMの論文のなかではstructual gateと記載)と、1つ目のLinear3Dの複雑さをコントロールするマトリクス\"Z\"(論文中ではfunctional gateと記載)が存在している ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce109df",
   "metadata": {},
   "source": [
    "#### この2つのマトリクスは要素に0か1の値をとる .　例えば、観測変数が3種類で$M$が、[[0,1,1],[0,0,1],[0,0,0]]であった場合、変数1から変数2と変数3へ因果がつながっている .　さらに変数2から変数3へもつながっている .　変数3からはどこへもつながっていない、ということになる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e292b36",
   "metadata": {},
   "source": [
    "#### ・Linear3Dの複雑さをコントロールするマトリクス$Z$の場合は、Linear3Dの出力要素のうち、$Z$の要素が0に対応する値には0が掛け算されて、実質的には使用されないようになる(結果、生成過程の複雑さが減る) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49cbdc0",
   "metadata": {},
   "source": [
    "#### ・以上の概念を図8.2.4に加えると、図8.2.5となる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e863668",
   "metadata": {},
   "source": [
    "![alt text](pict6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab11e28",
   "metadata": {},
   "source": [
    "#### ・ネットワーク構造を示すマトリクス$M$と、1つ目のLinear3Dの複雑さをコントロールするマトリクス$Z$は生成器Gのforward関数(順伝搬)の計算時に、生成器Gに与える ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41465042",
   "metadata": {},
   "source": [
    "#### ・生成器Gの学習時には、このネットワーク構造のマトリクス$M$と、複雑さマトリクス$Z$も学習させ、それぞれのマトリクスの各要素が0になるか1になるかを学習させる .　そして、このネットワーク構造のマトリクス$M$こそが、因果ダイアグラムの構造を示すマトリクスとなる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575e81a",
   "metadata": {},
   "source": [
    "## 因果構造マトリクス$M$と複雑さマトリクス$Z$について"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da982c07",
   "metadata": {},
   "source": [
    "#### ・この2つのマトリクスの学習について解説する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b5cdd",
   "metadata": {},
   "source": [
    "#### ・変数間の因果のつながり、因果ダイアグラムの形を示す因果構造マトリクス$M$と、生成器Gの1つ目の全結合の複雑さをコントロールするマトリクス$Z$は、どちらもその要素に0もしくは1の値をもつ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b32bd",
   "metadata": {},
   "source": [
    "#### ・しかしながら、ディープラーニングにおいて、0か1のような離散的な値をとる要素の学習方法は一般的ではない .　例えば、分類問題でもディープラーニングのネットワークからは最終的に連続値が出力され、その出力に対してソフトマックス関数を用いてクラス間で正規化して、最も大きな値を推論したラベルとしていた ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50afa99",
   "metadata": {},
   "source": [
    "#### ・このような離散値を学習させるためには、Gumbel-Softmaxと呼ばれる技術を利用する .　Gumbel-Softmaxを利用して0か1を要素にもつマトリクスを作るモジュールとして、MatrixSamplerを用意する .　今回、モジュールMatrixSamplerはLinear3D、ChannelBatchNorm1dと同じく、SAMオリジナルの実装モジュールを使用する . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31711e70",
   "metadata": {},
   "source": [
    "### ・本書では、「通常はディープラーニングでは連続値を出力して学習させるが、0、1のような離散値を出力できるモジュールもGumbel-Softmaxを利用すれば作ることができ、SAMではそれを使用している」程度に理解できていればよい ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e8d526",
   "metadata": {},
   "source": [
    "## 8-3 SAMの識別器Dと生成器Gの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5567643",
   "metadata": {},
   "source": [
    "#### ・本章では、7.5節でも使用した、疑似データ「上司向け : 部下とのキャリア面談のポイント研修」を使用する .　データの因果構造は図8.3.1の通りである .　観測変数は6種類で、$(x,Z,Y,Y2,Y3,Y4)$である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d59d79",
   "metadata": {},
   "source": [
    "![alt text](pict7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec9c4b",
   "metadata": {},
   "source": [
    "#### ・また、ネットワーク構造をマトリクスで表すと、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ef642",
   "metadata": {},
   "source": [
    "$$\n",
    "M = \\begin{pmatrix}\n",
    "0 & 1 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45265ce4",
   "metadata": {},
   "source": [
    "#### となる."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a5ff4",
   "metadata": {},
   "source": [
    "### プログラム前の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51adabc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.4.0+cu92 (from versions: 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for torch==1.4.0+cu92\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# PyTorchのバージョンを下げる\n",
    "!pip install torch==1.4.0+cu92 torchvision==0.5.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977f04fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)  # 元は1.5.0+cu101、versionを1.4に下げた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8157bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e21b0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するパッケージ（ライブラリと関数）を定義\n",
    "# 標準正規分布の生成用\n",
    "from numpy.random import *\n",
    "\n",
    "# グラフの描画用\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# その他\n",
    "import pandas as pd\n",
    "\n",
    "# シグモイド関数をimport\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7fb2ee",
   "metadata": {},
   "source": [
    "### データの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3189650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ数\n",
    "num_data = 2000\n",
    "\n",
    "# 部下育成への熱心さ\n",
    "x = np.random.uniform(low=-1, high=1, size=num_data)  # -1から1の一様乱数\n",
    "\n",
    "# 上司が「上司向け：部下とのキャリア面談のポイント研修」に参加したかどうか\n",
    "e_z = randn(num_data)  # ノイズの生成\n",
    "z_prob = expit(-5.0*x+5*e_z)\n",
    "Z = np.array([])\n",
    "\n",
    "# 上司が「上司向け：部下とのキャリア面談のポイント研修」に参加したかどうか\n",
    "for i in range(num_data):\n",
    "    Z_i = np.random.choice(2, size=1, p=[1-z_prob[i], z_prob[i]])[0]\n",
    "    Z = np.append(Z, Z_i)\n",
    "\n",
    "# 介入効果の非線形性：部下育成の熱心さxの値に応じて段階的に変化\n",
    "t = np.zeros(num_data)\n",
    "for i in range(num_data):\n",
    "    if x[i] < 0:\n",
    "        t[i] = 0.5\n",
    "    elif x[i] >= 0 and x[i] < 0.5:\n",
    "        t[i] = 0.7\n",
    "    elif x[i] >= 0.5:\n",
    "        t[i] = 1.0\n",
    "\n",
    "e_y = randn(num_data)\n",
    "Y = 2.0 + t*Z + 0.3*x + 0.1*e_y \n",
    "\n",
    "\n",
    "# 本章からの追加データを生成\n",
    "\n",
    "# Y2：部下当人のチームメンバへの満足度 1から5の5段階\n",
    "Y2 = np.random.choice([1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                      num_data, p=[0.1, 0.2, 0.3, 0.2, 0.2])\n",
    "\n",
    "# Y3：部下当人の仕事への満足度\n",
    "e_y3 = randn(num_data)\n",
    "Y3 = 3*Y + Y2 + e_y3\n",
    "\n",
    "# Y4：部下当人の仕事のパフォーマンス\n",
    "e_y4 = randn(num_data)\n",
    "Y4 = 3*Y3 + 2*e_y4 + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52b334",
   "metadata": {},
   "source": [
    "### データをまとめた表を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452da04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>Z</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.616961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.286924</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.732544</td>\n",
       "      <td>30.326507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.244218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.864636</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.743959</td>\n",
       "      <td>37.149014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.124545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.198515</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.569163</td>\n",
       "      <td>38.481185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.570717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.230572</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.312526</td>\n",
       "      <td>43.709229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.559952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.459267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.418739</td>\n",
       "      <td>40.833938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x    Z         Y   Y2         Y3         Y4\n",
       "0 -0.616961  1.0  2.286924  2.0   8.732544  30.326507\n",
       "1  0.244218  1.0  2.864636  3.0  10.743959  37.149014\n",
       "2 -0.124545  0.0  2.198515  3.0  10.569163  38.481185\n",
       "3  0.570717  1.0  3.230572  3.0  12.312526  43.709229\n",
       "4  0.559952  0.0  2.459267  5.0  12.418739  40.833938"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'x': x,\n",
    "                   'Z': Z,\n",
    "                   't': t,\n",
    "                   'Y': Y,\n",
    "                   'Y2': Y2,\n",
    "                   'Y3': Y3,\n",
    "                   'Y4': Y4,\n",
    "                   })\n",
    "\n",
    "del df[\"t\"]  # 変数tは観測できないので削除\n",
    "\n",
    "df.head()  # 先頭を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f543a4",
   "metadata": {},
   "source": [
    "## CausalDiscoveryToolboxのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619fbba3",
   "metadata": {},
   "source": [
    "#### ・SAM論文の著者らが整備している、SAMを含んだ因果探索のPythonパッケージ「CausalDiscoveryToolbox」をインストールする .　本章ではこのCausalDiscoveryToolboxにあるSAMの一部モジュール(Linear3D、ChannelBatchNorm1d、MatrixSampler)を使用する ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb59d659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cdt==0.5.18 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (0.5.18)\n",
      "Requirement already satisfied: GPUtil in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (1.4.0)\n",
      "Requirement already satisfied: joblib in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (1.5.1)\n",
      "Requirement already satisfied: networkx in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (3.5)\n",
      "Requirement already satisfied: numpy in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (2.2.5)\n",
      "Requirement already satisfied: pandas in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (2.2.3)\n",
      "Requirement already satisfied: requests in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (2.32.4)\n",
      "Requirement already satisfied: scikit-learn in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (1.15.3)\n",
      "Requirement already satisfied: skrebate in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (0.62)\n",
      "Requirement already satisfied: statsmodels in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (0.14.5)\n",
      "Requirement already satisfied: tqdm in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from cdt==0.5.18) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from pandas->cdt==0.5.18) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from pandas->cdt==0.5.18) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from pandas->cdt==0.5.18) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->cdt==0.5.18) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from requests->cdt==0.5.18) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from requests->cdt==0.5.18) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from requests->cdt==0.5.18) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from requests->cdt==0.5.18) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from scikit-learn->cdt==0.5.18) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from statsmodels->cdt==0.5.18) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/taihei/因果分析ゼミ/myenv/lib/python3.13/site-packages (from statsmodels->cdt==0.5.18) (25.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install cdt==0.5.18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b8065",
   "metadata": {},
   "source": [
    "## SAMの識別器Dの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735262f5",
   "metadata": {},
   "source": [
    "#### ・識別器Dをクラス「SAMDiscriminator」として実装する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ca710",
   "metadata": {},
   "source": [
    "#### ・実装するネットワーク構造は、全結合層、バッチノーマライゼーション、LeakyReLUを2回繰り返して、最後に全結合層で出力を得る(8.2節) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc36bd",
   "metadata": {},
   "source": [
    "#### ・SAMは、識別器Dも生成器Gもforward関数(順伝搬)が複雑である .　生成器Gで全観測変数を生成するのではなく、1変数のみを生成データ、他は観測データとするため、実装が複雑になる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc2253",
   "metadata": {},
   "source": [
    "#### ・識別器Dのforward計算は、入力が観測データのときは単純で、ネットワークに入力して判定するだけである .　入力が生成データの場合は複雑になる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc95c68",
   "metadata": {},
   "source": [
    "#### SAMの識別器Dの実装は以下の通りである ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f03f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorchから使用するものをimport\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SAMDiscriminator(nn.Module):\n",
    "    \"\"\"SAMのDiscriminatorのニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nfeatures, dnh, hlayers):\n",
    "        super(SAMDiscriminator, self).__init__()\n",
    "\n",
    "        # ----------------------------------\n",
    "        # ネットワークの用意\n",
    "        # ----------------------------------\n",
    "        self.nfeatures = nfeatures  # 入力変数の数\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(nfeatures, dnh))\n",
    "        layers.append(nn.BatchNorm1d(dnh))\n",
    "        layers.append(nn.LeakyReLU(.2))\n",
    "\n",
    "        for i in range(hlayers-1):\n",
    "            layers.append(nn.Linear(dnh, dnh))\n",
    "            layers.append(nn.BatchNorm1d(dnh))\n",
    "            layers.append(nn.LeakyReLU(.2))\n",
    "\n",
    "        layers.append(nn.Linear(dnh, 1))  # 最終出力\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # maskの用意（対角成分のみ1で、他は0の行列）\n",
    "        # ----------------------------------\n",
    "        mask = torch.eye(nfeatures, nfeatures)  # 変数の数×変数の数の単位行列\n",
    "        self.register_buffer(\"mask\", mask.unsqueeze(0))  # 単位行列maskを保存しておく\n",
    "\n",
    "        # 注意：register_bufferはmodelのパラメータではないが、その後forwardで使う変数を登録するPyTorchのメソッドです\n",
    "        # self.変数名で、以降も使用可能になります\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=register_buffer#torch.nn.Module.register_buffer\n",
    "def forward(self, input, obs_data=None):\n",
    "        \"\"\"順伝搬の計算\n",
    "        Args:\n",
    "            input (torch.Size([データ数, 観測変数の種類数])): 観測したデータ、もしくは生成されたデータ\n",
    "            obs_data (torch.Size([データ数, 観測変数の種類数])):観測したデータ\n",
    "        Returns:\n",
    "            torch.Tensor: 観測したデータか、それとも生成されたデータかの判定結果\n",
    "        \"\"\"\n",
    "\n",
    "        if obs_data is not None:\n",
    "          # 生成データを識別器に入力する場合\n",
    "            return [self.layers(i) for i in torch.unbind(obs_data.unsqueeze(1) * (1 - self.mask)\n",
    "                                                         + input.unsqueeze(1) * self.mask, 1)]\n",
    "            # 対角成分のみ生成したデータ、その他は観測データに\n",
    "            # データを各変数ごとに、生成したもの、その他観測したもので混ぜて、1変数ずつ生成したものを放り込む\n",
    "            # torch.unbind(x,1)はxの1次元目でテンソルをタプルに展開する\n",
    "            # minibatch数が2000、観測データの変数が6種類の場合、\n",
    "            # [2000,6]→[2000,6,6]→([2000,6], [2000,6], [2000,6], [2000,6], [2000,6], [2000,6])→([2000,1], [2000,1], [2000,1], [2000,1], [2000,1], [2000,1])\n",
    "            # returnは[torch.Size([2000, 1]),torch.Size([2000, 1]),torch.Size([2000, 1], torch.Size([2000, 1]),torch.Size([2000, 1]),torch.Size([2000, 1])]\n",
    "\n",
    "            # 注：生成した変数全種類を用いた判定はしない。\n",
    "            # すなわち、生成した変数1種類と、元の観測データたちをまとめて1つにし、それが観測結果か、生成結果を判定させる\n",
    "\n",
    "        else:\n",
    "            # 観測データを識別器に入力する場合\n",
    "\n",
    "            return self.layers(input)\n",
    "            # returnは[torch.Size([2000, 1])]\n",
    "\n",
    "def reset_parameters(self):\n",
    "        \"\"\"識別器Dの重みパラメータの初期化を実施\"\"\"\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea445efa",
   "metadata": {},
   "source": [
    "## 生成器Gの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1f38bb",
   "metadata": {},
   "source": [
    "#### ・続いてデータを生成する生成器Gを作成する .　この生成器Gに対して、観測データと同じ傾向を持つデータを生成する方法を学習させることで、データ生成のメカニズムを解き明かし、因果関係を明らかにする ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c034e8b",
   "metadata": {},
   "source": [
    "#### ・今回はSAMの著者らのパッケージから、3つのモジュール、Linear3D、ChannelBatchNorm1d、MatrixSamplerを利用する .　コード内にこれらのモジュールの実装へのリンクを記載する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbab98f",
   "metadata": {},
   "source": [
    "#### ・生成器Gの実装は以下の通りである .　Linear3Dの全結合層、バッチノーマライゼーション、活性化関数Tanh、そして再度Linear3Dの全結合層を通る(8.2節) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d475f",
   "metadata": {},
   "source": [
    "#### ・変数skeletonは、因果ダイアグラムの構造を示すマトリクスの変数adj_matrixにかけ算して、自分から自分への因果(adj_matrixの対角成分)を0にするために作成、使用している ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a8bf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU automatically detected. Setting SETTINGS.GPU to 0, and SETTINGS.NJOBS to cpu_count.\n"
     ]
    }
   ],
   "source": [
    "from cdt.utils.torch import ChannelBatchNorm1d, MatrixSampler, Linear3D\n",
    "\n",
    "\n",
    "class SAMGenerator(nn.Module):\n",
    "    \"\"\"SAMのGeneratorのニューラルネットワーク\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_shape, nh):\n",
    "        \"\"\"初期化\"\"\"\n",
    "        super(SAMGenerator, self).__init__()\n",
    "\n",
    "        # ----------------------------------\n",
    "        # 対角成分のみ0で、残りは1のmaskとなる変数skeletonを作成\n",
    "        # ※最後の行は、全部1です\n",
    "        # ----------------------------------\n",
    "        nb_vars = data_shape[1]  # 変数の数\n",
    "        skeleton = 1 - torch.eye(nb_vars + 1, nb_vars)\n",
    "\n",
    "        self.register_buffer('skeleton', skeleton)\n",
    "\n",
    "        # 注意：register_bufferはmodelのパラメータではないが、その後forwardで使う変数を登録するPyTorchのメソッドです\n",
    "        # self.変数名で、以降も使用可能になります\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=register_buffer#torch.nn.Module.register_buffer\n",
    "\n",
    "        # ----------------------------------\n",
    "        # ネットワークの用意\n",
    "        # ----------------------------------\n",
    "        # 入力層（SAMの形での全結合層）　\n",
    "        self.input_layer = Linear3D(\n",
    "            (nb_vars, nb_vars + 1, nh))  # nhは中間層のニューロン数\n",
    "        # https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/torch.py#L289\n",
    "\n",
    "        # 中間層\n",
    "        layers = []\n",
    "        # 2次元を1次元に変換してバッチノーマライゼーションするモジュール\n",
    "        layers.append(ChannelBatchNorm1d(nb_vars, nh))\n",
    "        layers.append(nn.Tanh())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "        # ChannelBatchNorm1d\n",
    "        # https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/torch.py#L130\n",
    "\n",
    "        # 出力層（再度、SAMの形での全結合層）\n",
    "        self.output_layer = Linear3D((nb_vars, nh, 1))\n",
    "            \n",
    "def forward(self, data, noise, adj_matrix, drawn_neurons=None):\n",
    "        \"\"\"順伝搬の計算\n",
    "        Args:\n",
    "            data (torch.Tensor): 観測データ\n",
    "            noise (torch.Tensor): データ生成用のノイズ\n",
    "            adj_matrix (torch.Tensor): 因果関係を示す因果構造マトリクスM\n",
    "            drawn_neurons (torch.Tensor): Linear3Dの複雑さを制御する複雑さマトリクスZ\n",
    "        Returns:\n",
    "            torch.Tensor: 生成されたデータ\n",
    "        \"\"\"\n",
    "\n",
    "        # 入力層\n",
    "        x = self.input_layer(data, noise, adj_matrix *\n",
    "                             self.skeleton)  # Linear3D\n",
    "\n",
    "        # 中間層（バッチノーマライゼーションとTanh）\n",
    "        x = self.layers(x)\n",
    "\n",
    "        # 出力層\n",
    "        output = self.output_layer(\n",
    "            x, noise=None, adj_matrix=drawn_neurons)  # Linear3D\n",
    "\n",
    "        return output.squeeze(2)\n",
    "\n",
    "def reset_parameters(self):\n",
    "        \"\"\"重みパラメータの初期化を実施\"\"\"\n",
    "\n",
    "        self.input_layer.reset_parameters()\n",
    "        self.output_layer.reset_parameters()\n",
    "\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09f967",
   "metadata": {},
   "source": [
    "## 因果構造マトリクス$M$と複雑さマトリクス$Z$の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf7cf9f",
   "metadata": {},
   "source": [
    "#### ・変数間の因果の関係性を示す因果構造マトリクス$M$と、生成器Gの1つ目の全結合の複雑さをコントロールするマトリクス$Z$は、どちらもその要素に0もしくは1の値をもつ .　前節で解説したようにこのような離散値を実現するためにGumbel-Softmaxを利用したモジュールを作成する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4e66c",
   "metadata": {},
   "source": [
    "#### ・本書ではこのモジュールはMatrixSamplerとして、SAMの著者らのモジュールを使用するので、この部分は実装しないとする ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990979ba",
   "metadata": {},
   "source": [
    "#### ・因果構造マトリクス$M$と複雑さマトリクス$Z$はSAMの生成器のforward関数の引数で使用されており、それぞれadj_matrixとdrawn_neuronsとしている(厳密には、adj_matrixは因果構造マトリクス$M$にノイズの項が加わったものである) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f682194",
   "metadata": {},
   "source": [
    "## 8-4 SAMの損失関数の解説と因果探索の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93127bbd",
   "metadata": {},
   "source": [
    "#### ・本章ではSAMの損失関数の解説と実装を行う .　また、SAMの学習を実施する部分も合わせて実装する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e25d81",
   "metadata": {},
   "source": [
    "## DAGを生み出す損失関数 : NO TEARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42575558",
   "metadata": {},
   "source": [
    "#### ・因果探索を行うにあたり、変数間の因果関係を示す因果構造マトリクス$M$がDAG(有向非循環グラフ)になるパターンを探索する必要がある .　そのため、因果構造マトリクス$M$がDAGでないときには損失を与え、DAGになるようにバックプロパゲーションで学習させる必要がある ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddc075",
   "metadata": {},
   "source": [
    "#### ・このマトリクスがDAGかどうかを判定する損失として、NO TEARS(Non-combinatorial Optimization via Trace Exponential and Augmented lagRangian for Structure learning)と呼ばれる手法が提案されている .　SAMでは損失関数にこのNO TEARSを利用する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58d225",
   "metadata": {},
   "source": [
    "#### ただし、論文NO TEARSそのものはディープラーニングによる因果探索の提案ではなく、DAGとなる拘束条件の与え方を示す論文である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9f3e0",
   "metadata": {},
   "source": [
    "#### ・NO TEARSによる損失計算の具体的な形は次の通りである .　因果構造マトリクス$M$がDAGの場合、以下の関係が成り立つ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc31e01",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{k=1}^d \\frac{\\mathrm{tr}\\, M^k}{k!} = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658316c",
   "metadata": {},
   "source": [
    "#### ここで、$d$は観測変数の種類数であり、マトリクスの行である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be54a277",
   "metadata": {},
   "source": [
    "#### ・因果構造マトリクス$M$がDAGではない場合、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee6880a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{k=1}^d \\frac{\\mathrm{tr}\\, M^k}{k!} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431317e",
   "metadata": {},
   "source": [
    "#### の値が0にならず、正の値をとる .　そのため、この項を損失関数に加えることで、因果構造マトリクス$M$がDAGになるように$M$を学習させることができる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfdeaae",
   "metadata": {},
   "source": [
    "#### ・NO TEARSの損失計算の実装は、SAMの著者らの実装をそのまま流用している ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa7f43",
   "metadata": {},
   "source": [
    "### SAMの誤差関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa63d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワークを示す因果構造マトリクスMがDAG（有向非循環グラフ）になるように加える損失\n",
    "\n",
    "def notears_constr(adj_m, max_pow=None):\n",
    "    \"\"\"No Tears constraint for binary adjacency matrixes. \n",
    "    Args:\n",
    "        adj_m (array-like): Adjacency matrix of the graph\n",
    "        max_pow (int): maximum value to which the infinite sum is to be computed.\n",
    "           defaults to the shape of the adjacency_matrix\n",
    "    Returns:\n",
    "        np.ndarray or torch.Tensor: Scalar value of the loss with the type\n",
    "            depending on the input.\n",
    "    参考：https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/loss.py#L215\n",
    "    \"\"\"\n",
    "    m_exp = [adj_m]\n",
    "    if max_pow is None:\n",
    "        max_pow = adj_m.shape[1]\n",
    "    while(m_exp[-1].sum() > 0 and len(m_exp) < max_pow):\n",
    "        m_exp.append(m_exp[-1] @ adj_m/len(m_exp))\n",
    "\n",
    "    return sum([i.diag().sum() for idx, i in enumerate(m_exp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927073b",
   "metadata": {},
   "source": [
    "## 識別器Dと生成器Gの損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73855f1e",
   "metadata": {},
   "source": [
    "#### ・SAMの論文では通常のGAN(正確にはDCGAN)の損失計算以外にも、ベイジアンネットワークの因果探索でのスコアリング法で用いられるMDL(Minimum Description Length)に基づく損失関数の使用が提案されている .　しかし、MDLに基づくGANの損失関数の導出と解説が難しいため、一般的なDCGANでの損失を使用する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55771e3d",
   "metadata": {},
   "source": [
    "#### ・まず識別器Dの損失関数です .　Binary cross entropy with Logistic functionと呼ばれる関数で損失を計算する .　PyTorchでは、Torch.nn.BCEWithLogisticLoss()として用意される .　式で記述すると、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff21e9",
   "metadata": {},
   "source": [
    "$$\n",
    "- \\sum_{i=1}^{N} \\left[ l_i \\log y_i + (1 - l_i) \\log (1 - y_i) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f92c5",
   "metadata": {},
   "source": [
    "#### となる .　ここで、$l_i$は$i$番目のデータのラベル(データセットのデータなら1、生成器Gから生成していれば0)を示し、$y_i$は識別器の出力を示す .　$N$はミニバッチのデータ数である ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7dec2",
   "metadata": {},
   "source": [
    "#### ・生成器Gは識別器Dを騙すようにしたいので、生成器Gの損失関数は識別器Dの損失関数にマイナスをかけた以下になる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca185204",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{i=1}^{N} \\left[ l_i \\log y_i + (1 - l_i) \\log (1 - y_i) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55e3e3",
   "metadata": {},
   "source": [
    "#### ここでは生成器Gだけを考えるため、$l_i$は0だけとなる .　そして$y_i$は生成されたデータを判定した結果なので、生成器Gの損失関数は、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd450b",
   "metadata": {},
   "source": [
    "$$\n",
    "+ \\sum_{i=1}^{N} \\log \\left(1 - D(G(z_i, x_i))\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5252722",
   "metadata": {},
   "source": [
    "#### となる .　ここで$z_i$はデータ生成のためのノイズ、$x_i$は観測データである .　通常のDCGANでは生成時に観測データを使用しないが、SAMは観測データを1変数ずつ生成するため、生成器Gに観測データ$x_i$を与えている ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa9286",
   "metadata": {},
   "source": [
    "#### ただし、上記の損失の形式では生成器Gの学習が進みづらいことが判明しているため、生成器Gの損失関数には上記を基にした"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20917a5e",
   "metadata": {},
   "source": [
    "$$\n",
    "- \\sum_{i=1}^{N} \\log \\left( D(G(z_i, x_i)) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f33a19",
   "metadata": {},
   "source": [
    "#### を使用する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4940a",
   "metadata": {},
   "source": [
    "## 生成器の複雑さの損失関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8999bd",
   "metadata": {},
   "source": [
    "#### ・因果構造マトリクス$M$と複雑さマトリクス$Z$は、マトリクスの要素が0から1に変わると、より複雑な生成過程を作ることができる .　できれば可能な限りシンプルでミニマムな要素数で生成過程を実現することが好ましい ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1be5ae",
   "metadata": {},
   "source": [
    "#### そこで、これらのマトリクスのうち、1である要素数の合計をそのまま損失関数として使用する .　以下の数式で表される ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa726023",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\lambda_s}{N} \\sum_{i,j} m_{i,j} + \\frac{\\lambda_F}{N} \\sum_{i,j} z_{i,j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0e4f0",
   "metadata": {},
   "source": [
    "#### ここで、${\\lambda_s}$と${\\lambda_F}$はこの損失の影響力を決める係数です .　$m_{i,j}$は因果構造マトリクス$M$の要素で0か1の値をとる .　$z_{i,j}$は複雑さマトリクス$Z$の要素で0か1の値をとる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec34ea",
   "metadata": {},
   "source": [
    "## SAMの学習を実装するコード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e1057",
   "metadata": {},
   "source": [
    "#### ・注意点の1つ目は、訓練epochでネットワークを学習させ、その後テストepochで因果構造マトリクス$M$と生成データの損失を求めている点である .　因果構造マトリクス$M$の要素は0か1の離散値だが、確率的に0か1に求まるので、実装コード内のテスト部分と損失関数計算部分では、0か1ではなく、1となる確率値を使用している ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c841b5",
   "metadata": {},
   "source": [
    "#### そして、テストepoch数の平均をとることで、因果構造マトリクス$M$とデータ生成の損失を求めている ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6b3b7",
   "metadata": {},
   "source": [
    "#### ・もう1つの注意点は、NO TEARSによる損失は訓練epochを経るに従い、線形的に強く影響するように与えている .　初めからDAGを制約すると上手く生成器Gが学習しづらいため、DAGの制約は徐々に強くしていく ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f52d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run_SAM(in_data, lr_gen, lr_disc, lambda1, lambda2, hlayers, nh, dnh, train_epochs, test_epochs, device):\n",
    "    '''SAMの学習を実行する関数'''\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 入力データの前処理\n",
    "    # ---------------------------------------------------\n",
    "    list_nodes = list(in_data.columns)  # 入力データの列名のリスト\n",
    "    data = scale(in_data[list_nodes].values)  # 入力データの正規化\n",
    "    nb_var = len(list_nodes)  # 入力データの数 = d\n",
    "    data = data.astype('float32')  # 入力データをfloat32型に\n",
    "    data = torch.from_numpy(data).to(device)  # 入力データをPyTorchのテンソルに\n",
    "    rows, cols = data.size()  # rowsはデータ数、colsは変数の数\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # DataLoaderの作成（バッチサイズは全データ）\n",
    "    # ---------------------------------------------------\n",
    "    batch_size = rows  # 入力データ全てを使用したミニバッチ学習とする\n",
    "    data_iterator = DataLoader(data, batch_size=batch_size,\n",
    "                               shuffle=True, drop_last=True)\n",
    "    # 注意：引数のdrop_lastはdataをbatch_sizeで取り出していったときに最後に余ったものは使用しない設定\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 【Generator】ネットワークの生成とパラメータの初期化\n",
    "    # cols：入力変数の数、nhは中間ニューロンの数、hlayersは中間層の数\n",
    "    # neuron_samplerは、Functional gatesの変数zを学習するネットワーク\n",
    "    # graph_samplerは、Structual gatesの変数aを学習するネットワーク\n",
    "    # ---------------------------------------------------\n",
    "    sam = SAMGenerator((batch_size, cols), nh).to(device)  # 生成器G\n",
    "    graph_sampler = MatrixSampler(nb_var, mask=None, gumbel=False).to(\n",
    "        device)  # 因果構造マトリクスMを作るネットワーク\n",
    "    neuron_sampler = MatrixSampler((nh, nb_var), mask=False, gumbel=True).to(\n",
    "        device)  # 複雑さマトリクスZを作るネットワーク\n",
    "\n",
    "    # 注意：MatrixSamplerはGumbel-Softmaxを使用し、0か1を出力させるニューラルネットワーク\n",
    "    # SAMの著者らの実装モジュール、MatrixSamplerを使用\n",
    "    # https://github.com/FenTechSolutions/CausalDiscoveryToolbox/blob/32200779ab9b63762be3a24a2147cff09ba2bb72/cdt/utils/torch.py#L212\n",
    "\n",
    "    # 重みパラメータの初期化\n",
    "    sam.reset_parameters()\n",
    "    graph_sampler.weights.data.fill_(2)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 【Discriminator】ネットワークの生成とパラメータの初期化\n",
    "    # cols：入力変数の数、dnhは中間ニューロンの数、hlayersは中間層の数。\n",
    "    # ---------------------------------------------------\n",
    "    discriminator = SAMDiscriminator(cols, dnh, hlayers).to(device)\n",
    "    discriminator.reset_parameters()  # 重みパラメータの初期化\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 最適化の設定\n",
    "    # ---------------------------------------------------\n",
    "    # 生成器\n",
    "\n",
    "    g_optimizer = optim.Adam(sam.parameters(), lr=lr_gen)\n",
    "    graph_optimizer = optim.Adam(graph_sampler.parameters(), lr=lr_gen)\n",
    "    neuron_optimizer = optim.Adam(neuron_sampler.parameters(), lr=lr_gen)\n",
    "\n",
    "    # 識別器\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr_disc)\n",
    "\n",
    "    # 損失関数\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # nn.BCEWithLogitsLoss()は、binary cross entropy with Logistic function\n",
    "    # https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss\n",
    "\n",
    "    # 損失関数のDAGに関する制約の設定パラメータ\n",
    "    dagstart = 0.5\n",
    "    dagpenalization_increase = 0.001*10\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # forward計算、および損失関数の計算に使用する変数を用意\n",
    "    # ---------------------------------------------------\n",
    "    _true = torch.ones(1).to(device)\n",
    "    _false = torch.zeros(1).to(device)\n",
    "\n",
    "    noise = torch.randn(batch_size, nb_var).to(device)  # 生成器Gで使用する生成ノイズ\n",
    "    noise_row = torch.ones(1, nb_var).to(device)\n",
    "\n",
    "    output = torch.zeros(nb_var, nb_var).to(device)  # 求まった隣接行列\n",
    "    output_loss = torch.zeros(1, 1).to(device)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # forwardの計算で、ネットワークを学習させる\n",
    "    # ---------------------------------------------------\n",
    "    pbar = tqdm(range(train_epochs + test_epochs))  # 進捗（progressive bar）の表示\n",
    "\n",
    "    for epoch in pbar:\n",
    "        for i_batch, batch in enumerate(data_iterator):\n",
    "\n",
    "            # 最適化を初期化\n",
    "            g_optimizer.zero_grad()\n",
    "            graph_optimizer.zero_grad()\n",
    "            neuron_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # 因果構造マトリクスM（drawn_graph）と複雑さマトリクスZ（drawn_neurons）をMatrixSamplerから取得\n",
    "            drawn_graph = graph_sampler()\n",
    "            drawn_neurons = neuron_sampler()\n",
    "            # (drawn_graph)のサイズは、torch.Size([nb_var, nb_var])。 出力値は0か1\n",
    "            # (drawn_neurons)のサイズは、torch.Size([nh, nb_var])。 出力値は0か1\n",
    "\n",
    "            # ノイズをリセットし、生成器Gで疑似データを生成\n",
    "            noise.normal_()\n",
    "            generated_variables = sam(data=batch, noise=noise,\n",
    "                                      adj_matrix=torch.cat(\n",
    "                                          [drawn_graph, noise_row], 0),\n",
    "                                      drawn_neurons=drawn_neurons)\n",
    "\n",
    "            # 識別器Dで判定\n",
    "            # 観測変数のリスト[]で、各torch.Size([data数, 1])が求まる\n",
    "            disc_vars_d = discriminator(generated_variables.detach(), batch)\n",
    "            # 観測変数のリスト[] で、各torch.Size([data数, 1])が求まる\n",
    "            disc_vars_g = discriminator(generated_variables, batch)\n",
    "            true_vars_disc = discriminator(batch)  # torch.Size([data数, 1])が求まる\n",
    "\n",
    "            # 損失関数の計算（DCGAN）\n",
    "            disc_loss = sum([criterion(gen, _false.expand_as(gen)) for gen in disc_vars_d]) / nb_var \\\n",
    "                + criterion(true_vars_disc, _true.expand_as(true_vars_disc))\n",
    "\n",
    "            gen_loss = sum([criterion(gen,\n",
    "                                      _true.expand_as(gen))\n",
    "                            for gen in disc_vars_g])\n",
    "            \n",
    "            # 損失の計算（SAM論文のオリジナルのfgan）\n",
    "            #disc_loss = sum([torch.mean(torch.exp(gen - 1)) for gen in disc_vars_d]) / nb_var - torch.mean(true_vars_disc)\n",
    "            #gen_loss = -sum([torch.mean(torch.exp(gen - 1)) for gen in disc_vars_g])\n",
    "\n",
    "            # 識別器Dのバックプロパゲーションとパラメータの更新\n",
    "            if epoch < train_epochs:\n",
    "                disc_loss.backward()\n",
    "                d_optimizer.step()\n",
    "\n",
    "            # 生成器のGの損失の計算の残り（マトリクスの複雑さとDAGのNO TEAR）\n",
    "            struc_loss = lambda1 / batch_size*drawn_graph.sum()     # Mのloss\n",
    "            func_loss = lambda2 / batch_size*drawn_neurons.sum()   # Aのloss\n",
    "\n",
    "            regul_loss = struc_loss + func_loss\n",
    "\n",
    "            if epoch <= train_epochs * dagstart:\n",
    "                # epochが基準前のときは、DAGになるようにMへのNO TEARSの制限はかけない\n",
    "                loss = gen_loss + regul_loss\n",
    "\n",
    "            else:\n",
    "                # epochが基準後のときは、DAGになるようにNO TEARSの制限をかける\n",
    "                filters = graph_sampler.get_proba()  # マトリクスMの要素を取得（ただし、0,1ではなく、1の確率）\n",
    "                dag_constraint = notears_constr(filters*filters)  # NO TERARの計算\n",
    "\n",
    "                # 徐々に線形にDAGの正則を強くする\n",
    "                loss = gen_loss + regul_loss + \\\n",
    "                    ((epoch - train_epochs * dagstart) *\n",
    "                     dagpenalization_increase) * dag_constraint\n",
    "\n",
    "            if epoch >= train_epochs:\n",
    "                # testのepochの場合、結果を取得\n",
    "                output.add_(filters.data)\n",
    "                output_loss.add_(gen_loss.data)\n",
    "            else:\n",
    "                # trainのepochの場合、生成器Gのバックプロパゲーションと更新\n",
    "                # retain_graph=Trueにすることで、以降3つのstep()が実行できる\n",
    "                loss.backward(retain_graph=True)\n",
    "                g_optimizer.step()\n",
    "                graph_optimizer.step()\n",
    "                neuron_optimizer.step()\n",
    "\n",
    "                # 進捗の表示\n",
    "            if epoch % 50 == 0:\n",
    "                pbar.set_postfix(gen=gen_loss.item()/cols,\n",
    "                                 disc=disc_loss.item(),\n",
    "                                 regul_loss=regul_loss.item(),\n",
    "                                 tot=loss.item())\n",
    "\n",
    "    return output.cpu().numpy()/test_epochs, output_loss.cpu().numpy()/test_epochs/cols  # Mと損失を出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353dd9fa",
   "metadata": {},
   "source": [
    "## 8-5 Google ColaboratoryでGPUを使用した因果探索の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82526b25",
   "metadata": {},
   "source": [
    "## Google ColaboratoryでGPUを使用する方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40031f3c",
   "metadata": {},
   "source": [
    "#### ・Google ColaboratoryでGPUを24時間以内に最長で12時間使用できる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d0396",
   "metadata": {},
   "source": [
    "#### ・GPU利用の手順を解説する .　ノートブックを開き、上部メニューの「ランタイム」を選択し、展開されたメニューから「ランタイムのタイプを変更」をクリックする(図8.5.1) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc256185",
   "metadata": {},
   "source": [
    "#### ・ノートブックの設定が開くので、「ハードウェアアクセラレータ」を\"GPU\"に設定し、右下の「保存」をクリックする(図8.5.2) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec854f2",
   "metadata": {},
   "source": [
    "![alt text](pict8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f52596",
   "metadata": {},
   "source": [
    "![alt text](pict9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028b47d",
   "metadata": {},
   "source": [
    "#### ・以下のコードを実行して、PyTorchからGPUが使用できるかを確認する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee39b84",
   "metadata": {},
   "source": [
    "### GPUの使用可能を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a8976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPUの使用確認：True or False\n",
    "torch.cuda.is_available()\n",
    "# 出力がTrueであれば、GPU使用の設定が完了."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25a297",
   "metadata": {},
   "source": [
    "## SAMの学習を実施"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c9085",
   "metadata": {},
   "source": [
    "#### ・SAMはGANを使った確率的な因果探索手法なので、結果は毎回変化する .　そこで、SAMの著者らは8回以上実行し、求まった結果の平均を使用することを推奨している ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426a14c",
   "metadata": {},
   "source": [
    "#### しかし、8回以上の実行は時間がかかるので、今回は5回の因果探索結果の平均を求めるように実行する ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0549da5",
   "metadata": {},
   "source": [
    "#### ・実装は以下の通りである .　なお、GPUで使われる乱数生成のseedを固定していないので実行結果は毎回微妙に異なる(PyTorchでGPU部分もseedを固定できるが、実行速度が落ちるので、今回は固定しない) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpyの出力を小数点2桁に\n",
    "np.set_printoptions(precision=2, floatmode='fixed', suppress=True)\n",
    "\n",
    "# 因果探索の結果を格納するリスト\n",
    "m_list = []\n",
    "loss_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    m, loss = run_SAM(in_data=df, lr_gen=0.01*0.5,\n",
    "                      lr_disc=0.01*0.5*2,\n",
    "                      #lambda1=0.01, lambda2=1e-05,\n",
    "                      lambda1=5.0*20, lambda2=0.005*20,\n",
    "                      hlayers=2,\n",
    "                      nh=200, dnh=200,\n",
    "                      train_epochs=10000,\n",
    "                      test_epochs=1000,\n",
    "                      device='cuda:0')\n",
    "\n",
    "    print(loss)\n",
    "    print(m)\n",
    "\n",
    "    m_list.append(m)\n",
    "    loss_list.append(loss)\n",
    "\n",
    "# ネットワーク構造（5回の平均）\n",
    "print(sum(m_list) / len(m_list))\n",
    "\n",
    "# mはこうなって欲しい\n",
    "#    x Z Y Y2 Y3 Y4\n",
    "# x  0 1 1 0 0 0\n",
    "# Z  0 0 1 0 0 0\n",
    "# Y  0 0 0 0 1 0\n",
    "# Y2 0 0 0 0 1 0\n",
    "# Y3 0 0 0 0 0 1\n",
    "# Y4 0 0 0 0 0 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ed1d5",
   "metadata": {},
   "source": [
    "#### ・下の図がSAMを実行した結果の様子である .　テストepochでの生成データの損失平均と、最終的に求まった因果構造マトリクス$M$のテストepochでの平均が、5試行分出力されている ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb546d",
   "metadata": {},
   "source": [
    "![alt text](pict10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b9b25",
   "metadata": {},
   "source": [
    "#### ・正解のネットワークは、変数$(x,Z,Y,Y2,Y3,Y4)$に対して、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e2950",
   "metadata": {},
   "source": [
    "$$\n",
    "M_{ans} =\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36b86f",
   "metadata": {},
   "source": [
    "#### であったが、SAMで因果探索を実行した結果、以下のように求まった ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4824926",
   "metadata": {},
   "source": [
    "$$\n",
    "M_{inference} =\n",
    "\\begin{pmatrix}\n",
    "0.00 & 0.81 & 0.62 & 0.01 & 0.14 & 0.03 \\\\\n",
    "0.11 & 0.00 & 0.63 & 0.00 & 0.20 & 0.26 \\\\\n",
    "0.16 & 0.42 & 0.00 & 1.00 & 0.85 & 0.34 \\\\\n",
    "0.20 & 0.00 & 0.00 & 0.00 & 0.09 & 0.01 \\\\\n",
    "0.05 & 0.00 & 0.03 & 0.99 & 0.00 & 0.84 \\\\\n",
    "0.06 & 0.01 & 0.08 & 0.13 & 0.25 & 0.00 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936ec5fc",
   "metadata": {},
   "source": [
    "#### ・ここで、適当に閾値を0.6と設定し、0.6以上であれば1、それ以下であれば0とすると、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf8107",
   "metadata": {},
   "source": [
    "$$\n",
    "M_{inference} =\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c325c59",
   "metadata": {},
   "source": [
    "#### となる .　正解の因果ダイアグラムと、SAMによる因果探索の結果を図で示すと以下のようになる .　探索した結果、求まったネットワークは完全に正確な結果ではないが、大まかな骨子はうまく推定できているように感じる .　一方で因果の矢印が逆になっている部分も見られる ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b3ac7",
   "metadata": {},
   "source": [
    "#### SAMのハイパーパラメータをチューニングしたりすると、もう少し正しい結果が得られるかもしれない .　SAMはハイパーパラメータが多く、その設定が難しいところが課題であると著者は感じている ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f266a43",
   "metadata": {},
   "source": [
    "![alt text](pict11.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
